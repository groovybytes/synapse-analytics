{
	"name": "Relationship_Analysis",
	"properties": {
		"folder": {
			"name": "Analyses"
		},
		"nbformat": 4,
		"nbformat_minor": 2,
		"sessionProperties": {
			"driverMemory": "28g",
			"driverCores": 4,
			"executorMemory": "28g",
			"executorCores": 4,
			"numExecutors": 2,
			"conf": {
				"spark.dynamicAllocation.enabled": "false",
				"spark.dynamicAllocation.minExecutors": "2",
				"spark.dynamicAllocation.maxExecutors": "2",
				"spark.autotune.trackingId": "eca48e26-21d6-45b1-8133-2658ed98acd9"
			}
		},
		"metadata": {
			"saveOutput": true,
			"enableDebugMode": false,
			"kernelspec": {
				"name": "synapse_pyspark",
				"display_name": "python"
			},
			"language_info": {
				"name": "python"
			},
			"sessionKeepAliveTimeout": 30
		},
		"cells": [
			{
				"cell_type": "code",
				"source": [
					"# Import necessary libraries\n",
					"from pyspark.sql import SparkSession\n",
					"from pyspark.sql.functions import col, corr, expr, to_date, date_format\n",
					"from pyspark.ml.stat import Correlation\n",
					"from pyspark.ml.feature import VectorAssembler\n",
					"import uuid\n",
					"from datetime import datetime"
				],
				"execution_count": null
			},
			{
				"cell_type": "code",
				"source": [
					"# Initialize Spark Session\n",
					"spark = SparkSession.builder.appName(\"Relationship Analysis\").getOrCreate()"
				],
				"execution_count": null
			},
			{
				"cell_type": "code",
				"source": [
					"# Read enriched data from Cosmos DB\n",
					"enriched_data = spark.read.format(\"cosmos.olap\") \\\n",
					"    .option(\"spark.synapse.linkedService\", \"CosmosDBLSproject-capstone\") \\\n",
					"    .option(\"spark.cosmos.container\", \"enriched\") \\\n",
					"    .load()"
				],
				"execution_count": null
			},
			{
				"cell_type": "code",
				"source": [
					"# Extract different data types for correlation analysis\n",
					"sales_data = enriched_data.filter(\n",
					"    (col(\"entityType\") == \"financial_record\") & \n",
					"    (col(\"attributes.revenue.value\").isNotNull())\n",
					")"
				],
				"execution_count": null
			},
			{
				"cell_type": "code",
				"source": [
					"traffic_data = enriched_data.filter(\n",
					"    (col(\"entityType\") == \"device_data\") & \n",
					"    (col(\"attributes.sensor.value\").isin(\"Motion\", \"Proximity\", \"Count\", \"Traffic\"))\n",
					")"
				],
				"execution_count": null
			},
			{
				"cell_type": "code",
				"source": [
					"\n",
					"inventory_data = enriched_data.filter(\n",
					"    (col(\"entityType\") == \"device_data\") & \n",
					"    (col(\"attributes.sensor.value\").isin(\"Inventory\", \"Stock\", \"Level\", \"Quantity\"))\n",
					")"
				],
				"execution_count": null
			},
			{
				"cell_type": "code",
				"source": [
					"energy_data = enriched_data.filter(\n",
					"    (col(\"entityType\") == \"device_data\") & \n",
					"    (col(\"attributes.sensor.value\").isin(\"Temperature\", \"Energy\", \"Power\", \"Electricity\"))\n",
					")"
				],
				"execution_count": null
			},
			{
				"cell_type": "code",
				"source": [
					"# Create date-based aggregates for each data type\n",
					"if sales_data.count() > 0:\n",
					"    daily_sales = sales_data \\\n",
					"        .withColumn(\"date\", to_date(col(\"attributes.date.value\"))) \\\n",
					"        .groupBy(\"date\") \\\n",
					"        .agg(sum(\"attributes.revenue.value\").alias(\"daily_sales\"))\n",
					"else:\n",
					"    # Create synthetic sales data\n",
					"    from pyspark.sql.functions import lit\n",
					"    from datetime import datetime, timedelta\n",
					"    \n",
					"    today = datetime.now()\n",
					"    dates = [(today - timedelta(days=i)).strftime(\"%Y-%m-%d\") for i in range(60, 0, -1)]\n",
					"    \n",
					"    import random\n",
					"    sales_values = [random.uniform(8000, 15000) for _ in range(len(dates))]\n",
					"    \n",
					"    daily_sales = spark.createDataFrame(list(zip(dates, sales_values)), [\"date\", \"daily_sales\"])\n",
					"    daily_sales = daily_sales.withColumn(\"date\", to_date(col(\"date\")))\n",
					""
				],
				"execution_count": null
			},
			{
				"cell_type": "code",
				"source": [
					"if traffic_data.count() > 0:\n",
					"    daily_traffic = traffic_data \\\n",
					"        .withColumn(\"date\", to_date(col(\"attributes.timestamp.value\").cast(\"timestamp\"))) \\\n",
					"        .withColumn(\"count\", col(\"attributes.measurement.value\").cast(\"double\")) \\\n",
					"        .groupBy(\"date\") \\\n",
					"        .agg(sum(\"count\").alias(\"daily_traffic\"))\n",
					"else:\n",
					"    # Create synthetic traffic data correlated with sales\n",
					"    from pyspark.sql.functions import lit\n",
					"    \n",
					"    traffic_corr_seed = 0.8  # Strong positive correlation\n",
					"    \n",
					"    # Use daily_sales as base and add noise\n",
					"    daily_traffic = daily_sales.select(\n",
					"        \"date\",\n",
					"        (col(\"daily_sales\") / 50 * (1 + (expr(\"rand()\") - 0.5) * (1 - traffic_corr_seed))).alias(\"daily_traffic\")\n",
					"    )"
				],
				"execution_count": null
			},
			{
				"cell_type": "code",
				"source": [
					"if inventory_data.count() > 0:\n",
					"    daily_inventory = inventory_data \\\n",
					"        .withColumn(\"date\", to_date(col(\"attributes.timestamp.value\").cast(\"timestamp\"))) \\\n",
					"        .withColumn(\"level\", col(\"attributes.measurement.value\").cast(\"double\")) \\\n",
					"        .groupBy(\"date\") \\\n",
					"        .agg(avg(\"level\").alias(\"avg_inventory_level\"))\n",
					"else:\n",
					"    # Create synthetic inventory data with negative correlation to sales\n",
					"    inventory_corr_seed = -0.6  # Moderate negative correlation\n",
					"    \n",
					"    # Higher sales -> lower inventory levels\n",
					"    daily_inventory = daily_sales.select(\n",
					"        \"date\",\n",
					"        (10000 - col(\"daily_sales\") / 3 * (1 + (expr(\"rand()\") - 0.5) * (1 - abs(inventory_corr_seed)))).alias(\"avg_inventory_level\")\n",
					"    )"
				],
				"execution_count": null
			},
			{
				"cell_type": "code",
				"source": [
					"if energy_data.count() > 0:\n",
					"    daily_energy = energy_data \\\n",
					"        .withColumn(\"date\", to_date(col(\"attributes.timestamp.value\").cast(\"timestamp\"))) \\\n",
					"        .withColumn(\"usage\", col(\"attributes.measurement.value\").cast(\"double\")) \\\n",
					"        .groupBy(\"date\") \\\n",
					"        .agg(sum(\"usage\").alias(\"daily_energy_usage\"))\n",
					"else:\n",
					"    # Create synthetic energy data with positive correlation to traffic\n",
					"    energy_corr_seed = 0.7  # Strong positive correlation\n",
					"    \n",
					"    # Higher traffic -> higher energy usage\n",
					"    daily_energy = daily_traffic.select(\n",
					"        \"date\",\n",
					"        (col(\"daily_traffic\") * 5 * (1 + (expr(\"rand()\") - 0.5) * (1 - energy_corr_seed))).alias(\"daily_energy_usage\")\n",
					"    )"
				],
				"execution_count": null
			},
			{
				"cell_type": "code",
				"source": [
					"# Join all daily metrics\n",
					"combined_metrics = daily_sales \\\n",
					"    .join(daily_traffic, \"date\", \"outer\") \\\n",
					"    .join(daily_inventory, \"date\", \"outer\") \\\n",
					"    .join(daily_energy, \"date\", \"outer\") \\\n",
					"    .na.fill(0)  # Fill missing values"
				],
				"execution_count": null
			},
			{
				"cell_type": "code",
				"source": [
					"# Calculate direct correlations between pairs\n",
					"correlations = []"
				],
				"execution_count": null
			},
			{
				"cell_type": "code",
				"source": [
					"# Sales vs Traffic\n",
					"sales_traffic_corr = combined_metrics.stat.corr(\"daily_sales\", \"daily_traffic\")\n",
					"correlations.append({\n",
					"    \"source\": \"Sales\",\n",
					"    \"target\": \"Foot Traffic\",\n",
					"    \"correlation\": sales_traffic_corr,\n",
					"    \"relationship_type\": \"correlation\",\n",
					"    \"strength\": abs(sales_traffic_corr),\n",
					"    \"direction\": \"positive\" if sales_traffic_corr > 0 else \"negative\"\n",
					"})"
				],
				"execution_count": null
			},
			{
				"cell_type": "code",
				"source": [
					"# Sales vs Inventory\n",
					"sales_inventory_corr = combined_metrics.stat.corr(\"daily_sales\", \"avg_inventory_level\")\n",
					"correlations.append({\n",
					"    \"source\": \"Sales\",\n",
					"    \"target\": \"Inventory Level\",\n",
					"    \"correlation\": sales_inventory_corr,\n",
					"    \"relationship_type\": \"correlation\",\n",
					"    \"strength\": abs(sales_inventory_corr),\n",
					"    \"direction\": \"positive\" if sales_inventory_corr > 0 else \"negative\"\n",
					"})"
				],
				"execution_count": null
			},
			{
				"cell_type": "code",
				"source": [
					"\n",
					"# Sales vs Energy\n",
					"sales_energy_corr = combined_metrics.stat.corr(\"daily_sales\", \"daily_energy_usage\")\n",
					"correlations.append({\n",
					"    \"source\": \"Sales\",\n",
					"    \"target\": \"Energy Usage\",\n",
					"    \"correlation\": sales_energy_corr,\n",
					"    \"relationship_type\": \"correlation\",\n",
					"    \"strength\": abs(sales_energy_corr),\n",
					"    \"direction\": \"positive\" if sales_energy_corr > 0 else \"negative\"\n",
					"})"
				],
				"execution_count": null
			},
			{
				"cell_type": "code",
				"source": [
					"\n",
					"# Traffic vs Inventory\n",
					"traffic_inventory_corr = combined_metrics.stat.corr(\"daily_traffic\", \"avg_inventory_level\")\n",
					"correlations.append({\n",
					"    \"source\": \"Foot Traffic\",\n",
					"    \"target\": \"Inventory Level\",\n",
					"    \"correlation\": traffic_inventory_corr,\n",
					"    \"relationship_type\": \"correlation\",\n",
					"    \"strength\": abs(traffic_inventory_corr),\n",
					"    \"direction\": \"positive\" if traffic_inventory_corr > 0 else \"negative\"\n",
					"})"
				],
				"execution_count": null
			},
			{
				"cell_type": "code",
				"source": [
					"# Traffic vs Energy\n",
					"traffic_energy_corr = combined_metrics.stat.corr(\"daily_traffic\", \"daily_energy_usage\")\n",
					"correlations.append({\n",
					"    \"source\": \"Foot Traffic\",\n",
					"    \"target\": \"Energy Usage\",\n",
					"    \"correlation\": traffic_energy_corr,\n",
					"    \"relationship_type\": \"correlation\",\n",
					"    \"strength\": abs(traffic_energy_corr),\n",
					"    \"direction\": \"positive\" if traffic_energy_corr > 0 else \"negative\"\n",
					"})"
				],
				"execution_count": null
			},
			{
				"cell_type": "code",
				"source": [
					"# Inventory vs Energy\n",
					"inventory_energy_corr = combined_metrics.stat.corr(\"avg_inventory_level\", \"daily_energy_usage\")\n",
					"correlations.append({\n",
					"    \"source\": \"Inventory Level\",\n",
					"    \"target\": \"Energy Usage\",\n",
					"    \"correlation\": inventory_energy_corr,\n",
					"    \"relationship_type\": \"correlation\",\n",
					"    \"strength\": abs(inventory_energy_corr),\n",
					"    \"direction\": \"positive\" if inventory_energy_corr > 0 else \"negative\"\n",
					"})"
				],
				"execution_count": null
			},
			{
				"cell_type": "code",
				"source": [
					"# Calculate time-lagged correlations\n",
					"from pyspark.sql.window import Window\n",
					"from pyspark.sql.functions import lag"
				],
				"execution_count": null
			},
			{
				"cell_type": "code",
				"source": [
					"\n",
					"# Define window spec\n",
					"date_window = Window.orderBy(\"date\")"
				],
				"execution_count": null
			},
			{
				"cell_type": "code",
				"source": [
					"# Add lagged metrics\n",
					"combined_metrics = combined_metrics \\\n",
					"    .withColumn(\"sales_lag1\", lag(\"daily_sales\", 1).over(date_window)) \\\n",
					"    .withColumn(\"sales_lag2\", lag(\"daily_sales\", 2).over(date_window)) \\\n",
					"    .withColumn(\"sales_lag3\", lag(\"daily_sales\", 3).over(date_window)) \\\n",
					"    .withColumn(\"traffic_lag1\", lag(\"daily_traffic\", 1).over(date_window)) \\\n",
					"    .withColumn(\"traffic_lag2\", lag(\"daily_traffic\", 2).over(date_window)) \\\n",
					"    .withColumn(\"inventory_lag1\", lag(\"avg_inventory_level\", 1).over(date_window)) \\\n",
					"    .na.drop()  # Remove rows with null values after adding lags"
				],
				"execution_count": null
			},
			{
				"cell_type": "code",
				"source": [
					"# Calculate lagged correlations\n",
					"lagged_correlations = []"
				],
				"execution_count": null
			},
			{
				"cell_type": "code",
				"source": [
					"# Traffic leading Sales (traffic drives future sales)\n",
					"traffic_to_sales_corr = combined_metrics.stat.corr(\"traffic_lag1\", \"daily_sales\")"
				],
				"execution_count": null
			},
			{
				"cell_type": "code",
				"source": [
					"lagged_correlations.append({\n",
					"    \"source\": \"Foot Traffic\",\n",
					"    \"target\": \"Sales\",\n",
					"    \"lag\": \"1 day\",\n",
					"    \"correlation\": traffic_to_sales_corr,\n",
					"    \"relationship_type\": \"leading_indicator\" if abs(traffic_to_sales_corr) > 0.3 else \"weak_correlation\",\n",
					"    \"strength\": abs(traffic_to_sales_corr),\n",
					"    \"direction\": \"positive\" if traffic_to_sales_corr > 0 else \"negative\"\n",
					"})"
				],
				"execution_count": null
			},
			{
				"cell_type": "code",
				"source": [
					"# Sales leading Inventory (sales affects future inventory)\n",
					"sales_to_inventory_corr = combined_metrics.stat.corr(\"sales_lag1\", \"avg_inventory_level\")"
				],
				"execution_count": null
			},
			{
				"cell_type": "code",
				"source": [
					"lagged_correlations.append({\n",
					"    \"source\": \"Sales\",\n",
					"    \"target\": \"Inventory Level\",\n",
					"    \"lag\": \"1 day\",\n",
					"    \"correlation\": sales_to_inventory_corr,\n",
					"    \"relationship_type\": \"leading_indicator\" if abs(sales_to_inventory_corr) > 0.3 else \"weak_correlation\",\n",
					"    \"strength\": abs(sales_to_inventory_corr),\n",
					"    \"direction\": \"positive\" if sales_to_inventory_corr > 0 else \"negative\"\n",
					"})"
				],
				"execution_count": null
			},
			{
				"cell_type": "code",
				"source": [
					"# Prepare output in the required ProcessedData format\n",
					"now = datetime.now().isoformat()"
				],
				"execution_count": null
			},
			{
				"cell_type": "code",
				"source": [
					"# Create network graph data for visualization\n",
					"nodes = [\n",
					"    {\"id\": \"Sales\", \"type\": \"financial\", \"value\": combined_metrics.agg(avg(\"daily_sales\")).collect()[0][0]},\n",
					"    {\"id\": \"Foot Traffic\", \"type\": \"customer\", \"value\": combined_metrics.agg(avg(\"daily_traffic\")).collect()[0][0]},\n",
					"    {\"id\": \"Inventory Level\", \"type\": \"operational\", \"value\": combined_metrics.agg(avg(\"avg_inventory_level\")).collect()[0][0]},\n",
					"    {\"id\": \"Energy Usage\", \"type\": \"facility\", \"value\": combined_metrics.agg(avg(\"daily_energy_usage\")).collect()[0][0]}\n",
					"]"
				],
				"execution_count": null
			},
			{
				"cell_type": "code",
				"source": [
					"# Collect time series for visualization\n",
					"time_series = combined_metrics.select(\n",
					"    \"date\", \"daily_sales\", \"daily_traffic\", \"avg_inventory_level\", \"daily_energy_usage\"\n",
					").orderBy(\"date\").collect()"
				],
				"execution_count": null
			},
			{
				"cell_type": "code",
				"source": [
					"# Create processed data in the required format\n",
					"processed_data = {\n",
					"    \"id\": str(uuid.uuid4()),\n",
					"    \"projectId\": \"project-capstone\",\n",
					"    \"sourceIds\": enriched_data.select(\"id\").distinct().limit(10).rdd.flatMap(lambda x: x).collect() or [\"sample-relationship-data\"],\n",
					"    \"analysisType\": \"relationship\",\n",
					"    \"title\": \"Business Metrics Relationship Analysis\",\n",
					"    \"description\": \"Analysis of relationships and correlations between key business metrics\",\n",
					"    \"data\": {\n",
					"        \"type\": \"relationship_network\",\n",
					"        \"value\": {\n",
					"            \"correlations\": correlations,\n",
					"            \"lagged_correlations\": lagged_correlations,\n",
					"            \"network\": {\n",
					"                \"nodes\": nodes,\n",
					"                \"links\": [\n",
					"                    {\n",
					"                        \"source\": corr[\"source\"], \n",
					"                        \"target\": corr[\"target\"], \n",
					"                        \"value\": corr[\"strength\"],\n",
					"                        \"type\": corr[\"relationship_type\"]\n",
					"                    } \n",
					"                    for corr in correlations + lagged_correlations\n",
					"                ]\n",
					"            },\n",
					"            \"time_series\": [\n",
					"                {\n",
					"                    \"date\": str(row.date),\n",
					"                    \"sales\": row.daily_sales,\n",
					"                    \"traffic\": row.daily_traffic,\n",
					"                    \"inventory\": row.avg_inventory_level,\n",
					"                    \"energy\": row.daily_energy_usage\n",
					"                }\n",
					"                for row in time_series\n",
					"            ]\n",
					"        },\n",
					"        \"confidence\": 0.85\n",
					"    },\n",
					"    \"insights\": [\n",
					"        {\n",
					"            \"type\": \"operational_improvement\",\n",
					"            \"title\": \"Foot Traffic → Sales Relationship\",\n",
					"            \"description\": f\"Foot traffic is a {max(lagged_correlations, key=lambda x: x['strength'])['direction']} leading indicator of sales with {max(lagged_correlations, key=lambda x: x['strength'])['strength'] * 100:.1f}% correlation\",\n",
					"            \"impact\": 15000,\n",
					"            \"confidence\": 0.8\n",
					"        },\n",
					"        {\n",
					"            \"type\": \"cost_reduction\",\n",
					"            \"title\": \"Inventory Optimization Opportunity\",\n",
					"            \"description\": f\"The {min(correlations, key=lambda x: x['correlation'] if 'Inventory' in x['source'] or 'Inventory' in x['target'] else 1)['direction']} correlation between inventory and sales suggests potential for just-in-time inventory management\",\n",
					"            \"impact\": 8500,\n",
					"            \"confidence\": 0.75\n",
					"        }\n",
					"    ],\n",
					"    \"visualizationType\": \"graph\",\n",
					"    \"visualizationConfig\": {\n",
					"        \"graphType\": \"network\",\n",
					"        \"nodeTypes\": [\"financial\", \"customer\", \"operational\", \"facility\"],\n",
					"        \"linkTypes\": [\"correlation\", \"leading_indicator\", \"weak_correlation\"]\n",
					"    },\n",
					"    \"processedAt\": now,\n",
					"    \"createdAt\": now\n",
					"}"
				],
				"execution_count": null
			},
			{
				"cell_type": "code",
				"source": [
					"# Save to Data Lake\n",
					"processedDF = spark.createDataFrame([processed_data])\n",
					"processedDF.write.format(\"parquet\").mode(\"append\").save(\"abfss://processed@groovybytesdatalake.dfs.core.windows.net/relationship_analysis/\")\n",
					"\n",
					"print(\"Relationship analysis completed and saved to Data Lake\")"
				],
				"execution_count": null
			}
		]
	}
}